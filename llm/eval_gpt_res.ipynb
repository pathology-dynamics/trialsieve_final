{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-03 09:50:27.279745: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-03 09:50:28.068047: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import json\n",
    "openai.api_key = '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'\n",
    "from thefuzz import fuzz, process\n",
    "import re\n",
    "import ujson\n",
    "import logging\n",
    "import inflect\n",
    "from collections import Counter, defaultdict\n",
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import evaluate\n",
    "import spacy\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# seqeval evaluation\n",
    "seqeval = evaluate.load(\"seqeval\")\n",
    "\n",
    "# spacy tokenizer\n",
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "# Create an engine object\n",
    "p = inflect.engine()\n",
    "# Set up logging configuration\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpt label --> trial_sieve label\n",
    "remapped_keys = {\n",
    "    \"disease\" : \"Disease/Condition of Interest\", \n",
    "    \"drug_intervention\" : \"Drug Intervention\", \n",
    "    \"drug_dosage\" : \"Dosage\", \n",
    "    \"sample_size\" : \"Sample Size\", \n",
    "    \"follow_up_period\" : \"Follow-up period\", \n",
    "    \"group_characteristic\" : \"Group Characteristic\", \n",
    "    \"group_name\" : \"Group Name\", \n",
    "    \"intervention_administration\" : \"Intervention Administration\", \n",
    "    \"intervention_duration\" : \"Intervention Duration\", \n",
    "    \"intervention_frequency\" : \"Intervention Frequency\", \n",
    "    \"non_pharmaceutical_intervention\" : \"Non-Pharmaceutical Intervention\", \n",
    "    \"non_study_drug\" : \"Non-Study Drug\", \n",
    "    \"outcome\" : \"Outcome (Study Endpoint)\", \n",
    "    \"qualitative_side_effects\" : \"Qualitative Side Effects\", \n",
    "    \"quantitative_measurement\" : \"Quantitative Measurement\", \n",
    "    \"statistical_significance\" : \"Statistical Significance\", \n",
    "    \"study_duration\" : \"Study Duration\", \n",
    "    \"study_years\" : \"Study Years\", \n",
    "    \"type_of_quant_measure\" : \"Type of Quant. Measure\", \n",
    "    \"units\" : \"Units\",\n",
    "}\n",
    "\n",
    "tag_to_label = {\n",
    "    \"disease\" : 8, #\n",
    "    \"drug_dosage\" : 9, #\n",
    "    \"drug_intervention\" : 1 , #\n",
    "    \"follow_up_period\" : 16, # \n",
    "    \"group_characteristic\" : 6, # \n",
    "    \"group_name\" : 3,#  \n",
    "    \"sample_size\" : 7, # \n",
    "    \"intervention_administration\" : 13, # \n",
    "    \"intervention_duration\" : 12, # \n",
    "    \"intervention_frequency\" : 11, #  \n",
    "    \"non_pharmaceutical_intervention\" : 17, # \n",
    "    \"non_study_drug\" : 14, # \n",
    "    \"outcome\" : 2, # \n",
    "    \"qualitative_side_effects\" : 15, # \n",
    "    \"quantitative_measurement\" : 0, # \n",
    "    \"statistical_significance\" : 5, #\n",
    "    \"study_duration\" : 19, # \n",
    "    \"study_years\" : 18, #\n",
    "    \"type_of_quant_measure\" : 10, # \n",
    "    \"units\" : 4, #\n",
    "}\n",
    "\n",
    "extraction_keys = [\n",
    "    \"disease\", \n",
    "    \"drug_intervention\", \n",
    "    \"drug_dosage\", \n",
    "    \"sample_size\", \n",
    "    \"follow_up_period\", \n",
    "    \"group_characteristic\", \n",
    "    \"group_name\", \n",
    "    \"intervention_administration\", \n",
    "    \"intervention_duration\", \n",
    "    \"intervention_frequency\", \n",
    "    \"non_pharmaceutical_intervention\", \n",
    "    \"non_study_drug\", \n",
    "    \"outcome\", \n",
    "    \"qualitative_side_effects\", \n",
    "    \"quantitative_measurement\", \n",
    "    \"statistical_significance\", \n",
    "    \"study_duration\", \n",
    "    \"study_years\", \n",
    "    \"type_of_quant_measure\", \n",
    "    \"units\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_processed_for_modeling = \"/home2/cye73/gpt-meta-analysis/tests/processed_for_modeling.json\"\n",
    "with open(path_to_processed_for_modeling, \"r\") as file:\n",
    "    processed_for_modeling = ujson.load(file)\n",
    "documents = processed_for_modeling\n",
    "\n",
    "with open(\"/home2/cye73/gpt-meta-analysis/tests/data/abbreviations.json\", \"r\") as file:\n",
    "    abbreviations = ujson.load(file)\n",
    "    \n",
    "\n",
    "path_to_gpt_output1 = '/home2/cye73/gpt-meta-analysis/tests/results/2024-06-28/12:04:43/extraction/output.jsonl'\n",
    "\n",
    "gpt_output1 = []\n",
    "with open(path_to_gpt_output1, 'r') as file:\n",
    "    for line in file:\n",
    "        gpt_output1.append(json.loads(line))\n",
    "    \n",
    "gpt_pmids1 = [int(el['pmid']) for el in gpt_output1]\n",
    "\n",
    "pmid_to_output = {entry['pmid']: entry for entry in gpt_output1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 1 : Remap every entities extracted by GPT to the original abstract\n",
    "## Functions to process the data in the correct format (same as human annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extracted_gpt_output(path_to_gpt_output, extraction_keys):\n",
    "    '''\n",
    "    Extracts the relevant information from GPT output : Only keep the keys from TrialSieve labels\n",
    "    ----------------\n",
    "    path_to_gpt_output: str\n",
    "        Path to the GPT output file\n",
    "    extraction_keys: list\n",
    "        List of keys to extract from the dictionary\n",
    "    '''\n",
    "    extracted_data = {}\n",
    "    with open(path_to_gpt_output, 'r') as file:\n",
    "        data = json.load(file)\n",
    "        for key in extraction_keys:\n",
    "            if key in data:\n",
    "                extracted_data[key] = data[key]\n",
    "    return extracted_data\n",
    "\n",
    "def extracted_gpt_output_trialsieve(gpt_output, extraction_keys):\n",
    "    '''\n",
    "    Extracts the relevant information from GPT output : Only keep the keys from TrialSieve labels\n",
    "    ----------------\n",
    "    path_to_gpt_output: str\n",
    "        Path to the GPT output file\n",
    "    extraction_keys: list\n",
    "        List of keys to extract from the dictionary\n",
    "    '''\n",
    "    extracted_data = {}\n",
    "    for key in extraction_keys:\n",
    "        if key in gpt_output:\n",
    "            extracted_data[key] = gpt_output[key]\n",
    "    return extracted_data\n",
    "\n",
    "\n",
    "def convert_percentages(text):\n",
    "    '''Converts percentages in the text to per cent'''\n",
    "    return re.sub(r'(\\d+)%', r'\\1 per cent', text)\n",
    "\n",
    "def process_extracted_gpt_output(extracted_output, abbrevs):\n",
    "    '''\n",
    "    Convert the output.jsonl file from gpt with format {label : mention} to format: {mention : label}\n",
    "    Remove the mentions with \"not provided\" values\n",
    "    Normalize the percentages in the mentions\n",
    "    Enrich the set of plausible mentions by splitting the mentions with \"and\"\n",
    "    Enrich the set of plausible mentions by adding the abbreviations\n",
    "    ----------------\n",
    "    extracted_output: dict\n",
    "        The extracted output from the GPT model\n",
    "    abbrevs: dict\n",
    "        The dictionary of abbreviations for the current pmid\n",
    "    '''\n",
    "    tagged_text = {}\n",
    "    for key, value in extracted_output.items():\n",
    "        # if value is None or value =='' or value == \"N/A\" or value == \"not provided\":\n",
    "        if value == \"N/A\" :\n",
    "            continue\n",
    "        values = value.split('||')\n",
    "        for v in values :\n",
    "            # v2 = v.split('and')\n",
    "            # for v in v2 :\n",
    "            v = v.strip()\n",
    "            if not v :\n",
    "                continue\n",
    "            tagged_text[v] = key\n",
    "            # for abbrev, deabbrev in abbrevs.items():\n",
    "            #     if abbrev == v :\n",
    "            #         tagged_text[deabbrev] = key\n",
    "            #     elif deabbrev == v :\n",
    "            #         tagged_text[abbrev] = key\n",
    "            if v.isdigit():\n",
    "                word = p.number_to_words(v)\n",
    "                tagged_text[word] = key\n",
    "            if \"%\" in v :\n",
    "                new_v = convert_percentages(v)\n",
    "                tagged_text[new_v] = key\n",
    "    \n",
    "    return tagged_text\n",
    "\n",
    "def extract_tagged_text(abstract, tagged_text):\n",
    "    '''\n",
    "    Function to extract the position of the tagged text from the abstract\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    abstract : str\n",
    "        The abstract text\n",
    "    tagged_text : dict\n",
    "    '''\n",
    "    output = []\n",
    "    for key, value in tagged_text.items():\n",
    "        l = len(key)\n",
    "        key = key.strip()\n",
    "        if l == 1 or l==2:  # Handle single and double character abbreviations issues\n",
    "            # Create a regex pattern to match standalone single characters\n",
    "            pattern = r'\\b{}\\b'.format(re.escape(key))\n",
    "            matches = re.finditer(pattern, abstract, re.IGNORECASE)\n",
    "            for match in matches:\n",
    "                output.append({\n",
    "                    \"start\": match.start(),\n",
    "                    \"end\": match.end(),\n",
    "                    \"label\" : tag_to_label[value],\n",
    "                    \"tag\": remapped_keys[value],\n",
    "                    \"text\": match.group()\n",
    "                })\n",
    "        else:\n",
    "            # Handle multi-character keys\n",
    "            for i in range(len(abstract)):\n",
    "                if abstract[i:i+l].lower() == key.lower():\n",
    "                    output.append({\n",
    "                        \"start\": i,\n",
    "                        \"end\": i+l,\n",
    "                        \"label\" : tag_to_label[value],\n",
    "                        \"tag\": remapped_keys[value],\n",
    "                        \"text\": key\n",
    "                    })\n",
    "    \n",
    "    output.sort(key = lambda x: x[\"start\"])\n",
    "    return output\n",
    "\n",
    "def retrieve_abstract_and_spans(path_to_processed_for_modeling, pmid):\n",
    "    ''' \n",
    "    Function to retrieve the abstract and spans from the processed_for_modeling.json file\n",
    "    ----------\n",
    "    path_to_processed_for_modeling : str\n",
    "        The path to the processed_for_modeling.json file\n",
    "    pmid : int\n",
    "        The pmid of the article to retrieve the spans\n",
    "    '''\n",
    "    with open(path_to_processed_for_modeling, \"r\") as file:\n",
    "        processed_for_modeling = ujson.load(file)\n",
    "    spans = None\n",
    "    for article in processed_for_modeling:\n",
    "        if article[\"pmid\"] == pmid:\n",
    "            abstract = article[\"text\"]\n",
    "            spans = article[\"spans\"]\n",
    "            break\n",
    "    if spans is None:\n",
    "        logging.info(\"pmid not found in the list of documents\")\n",
    "    \n",
    "    return abstract, spans\n",
    "\n",
    "\n",
    "def tagged_abstract(path_to_processed_for_modeling, pmid):\n",
    "    '''\n",
    "    Function to retrieve the tagged abstract from the processed_for_modeling.json file\n",
    "    ----------\n",
    "    path_to_processed_for_modeling : str\n",
    "        The path to the processed_for_modeling.json file\n",
    "    pmid : int\n",
    "        The pmid of the article to retrieve the spans\n",
    "    '''\n",
    "    with open(path_to_processed_for_modeling, \"r\") as file:\n",
    "        processed_for_modeling = ujson.load(file)\n",
    "    tagged_abstract = defaultdict(list)\n",
    "    for article in processed_for_modeling:\n",
    "        if article[\"pmid\"] == pmid:\n",
    "            for span in article[\"spans\"]:\n",
    "                tagged_abstract[span[\"tag\"]].append(span[\"text\"])\n",
    "    return tagged_abstract\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to evaluate using seqeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_seqeval_format(y_true, y_pred, abstract):\n",
    "    '''\n",
    "    This function converts the entity data to seqeval format\n",
    "    Parameters:\n",
    "    ----------\n",
    "    y_true : list\n",
    "        Human annotated data\n",
    "    y_pred : list\n",
    "        Model predictions\n",
    "    abstract : str\n",
    "        The abstract to convert to seqeval format\n",
    "    '''\n",
    "    def label_tokens(annotations, abstract):\n",
    "        tokens = abstract.split()\n",
    "        labels = [\"O\"] * len(tokens)\n",
    "        for ann in annotations:\n",
    "            start_idx = len(abstract[:ann['start']].split())\n",
    "            end_idx = start_idx + len(ann['text'].split())\n",
    "            labels[start_idx] = f\"B-{ann['tag']}\"\n",
    "            for i in range(start_idx + 1, end_idx):\n",
    "                labels[i] = f\"I-{ann['tag']}\"\n",
    "        return labels\n",
    "    \n",
    "    y_true_seqeval = label_tokens(y_true, abstract)\n",
    "    y_pred_seqeval = label_tokens(y_pred, abstract)\n",
    "    return y_true_seqeval, y_pred_seqeval\n",
    "\n",
    "def label_tokens_from_offsets(text, annotations):\n",
    "    doc = nlp(text)\n",
    "    tokens = [token.text for token in doc]\n",
    "    labels = [\"O\"] * len(tokens)\n",
    "\n",
    "    for ann in annotations:\n",
    "        start_char = ann['start']\n",
    "        end_char = ann['end']\n",
    "        start_token = next((i for i, token in enumerate(doc) if token.idx >= start_char), None)\n",
    "        end_token = next((i for i, token in enumerate(doc) if token.idx >= end_char), None)\n",
    "        \n",
    "        if start_token is not None and end_token is not None:\n",
    "            labels[start_token] = f\"B-{ann['tag']}\"\n",
    "            for i in range(start_token + 1, end_token):\n",
    "                labels[i] = f\"I-{ann['tag']}\"\n",
    "\n",
    "    return labels\n",
    "\n",
    "def compute_metrics_v1(pmids) :\n",
    "    all_y_true_seqeval = []\n",
    "    all_y_pred_seqeval = []\n",
    "    results_list = []\n",
    "    \n",
    "    for i in range(len(pmids)):\n",
    "        abbrevs = abbreviations[f\"{pmids[i]}\"]\n",
    "        abstract, true_spans = retrieve_abstract_and_spans(path_to_processed_for_modeling, pmids[i])\n",
    "        extracted_output = extracted_gpt_output_trialsieve(gpt_output=pmid_to_output[f\"{pmids[i]}\"], extraction_keys = extraction_keys)\n",
    "        tagged_text = process_extracted_gpt_output(extracted_output = extracted_output, abbrevs=abbrevs)\n",
    "        pred_spans = extract_tagged_text(abstract, tagged_text)\n",
    "    \n",
    "        y_true_seqeval = label_tokens_from_offsets(text = abstract, annotations = true_spans)\n",
    "        y_pred_seqeval = label_tokens_from_offsets(text = abstract, annotations = pred_spans)\n",
    "        all_y_true_seqeval.append(y_true_seqeval)\n",
    "        all_y_pred_seqeval.append(y_pred_seqeval)\n",
    "        \n",
    "        if i%100 == 0:\n",
    "            print(\"i :\", i)\n",
    "        \n",
    "        results = seqeval.compute(predictions=[y_pred_seqeval], references=[y_true_seqeval])\n",
    "        results['pmid'] = pmids[i]\n",
    "        results_list.append(results)\n",
    "\n",
    "        \n",
    "    # Evaluate using seqeval\n",
    "    overall_results = seqeval.compute(predictions=all_y_pred_seqeval, references=all_y_true_seqeval)\n",
    "    overall_class_specific_f1 = {\n",
    "        k: v[\"f1\"] for k, v in overall_results.items() if not k.startswith(\"overall\")\n",
    "    }\n",
    "\n",
    "    \n",
    "    df_results = pd.DataFrame(results_list)\n",
    "    columns = ['pmid', 'overall_accuracy', 'overall_precision', 'overall_recall', 'overall_f1'] # + \\\n",
    "                    # [col for col in df_results.columns if col not in ['pmid', 'overall_accuracy', 'overall_precision', 'overall_recall', 'overall_f1']]\n",
    "    df_results = df_results[columns].rename(columns={\n",
    "        'overall_accuracy': 'accuracy',\n",
    "        'overall_precision': 'precision',\n",
    "        'overall_recall': 'recall',\n",
    "        'overall_f1': 'f1'\n",
    "    })\n",
    "    \n",
    "    return {\n",
    "        \"accuracy\": overall_results[\"overall_accuracy\"],\n",
    "        \"precision\": overall_results[\"overall_precision\"],\n",
    "        \"recall\": overall_results[\"overall_recall\"],\n",
    "        \"f1\": overall_results[\"overall_f1\"],\n",
    "        \"class_specific_f1\": overall_class_specific_f1,\n",
    "        \"detailed_results\": overall_results,\n",
    "    }, df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i : 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cye73/.conda/envs/gpt-meta-analysis/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/cye73/.conda/envs/gpt-meta-analysis/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i : 100\n",
      "i : 200\n",
      "i : 300\n",
      "i : 400\n",
      "i : 500\n",
      "i : 600\n",
      "i : 700\n",
      "i : 800\n",
      "i : 900\n",
      "i : 1000\n",
      "i : 1100\n",
      "i : 1200\n",
      "i : 1300\n",
      "i : 1400\n"
     ]
    }
   ],
   "source": [
    "results1, pd1 = compute_metrics_v1(pmids = gpt_pmids1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8101238359720483,\n",
       " 'precision': 0.42624267716843983,\n",
       " 'recall': 0.4450877695486722,\n",
       " 'f1': 0.4354614329893812,\n",
       " 'class_specific_f1': {'Disease/Condition of Interest': 0.3687053493640007,\n",
       "  'Dosage': 0.6073182322192302,\n",
       "  'Drug Intervention': 0.5320186250342371,\n",
       "  'Follow-up period': 0.2956989247311828,\n",
       "  'Group Characteristic': 0.06653825949921205,\n",
       "  'Group Name': 0.30717564088212246,\n",
       "  'Intervention Administration': 0.5452337583485124,\n",
       "  'Intervention Duration': 0.44305772230889234,\n",
       "  'Intervention Frequency': 0.5055578427336351,\n",
       "  'Non-Pharmaceutical Intervention': 0.17363344051446947,\n",
       "  'Non-Study Drug': 0.15906886517943744,\n",
       "  'Outcome (Study Endpoint)': 0.12532751091703054,\n",
       "  'Qualitative Side Effects': 0.0,\n",
       "  'Quantitative Measurement': 0.5137703780783905,\n",
       "  'Sample Size': 0.5893254262416605,\n",
       "  'Side Effects': 0.0,\n",
       "  'Statistical Significance': 0.782661596958175,\n",
       "  'Study Duration': 0.27790432801822323,\n",
       "  'Study Years': 0.42402826855123676,\n",
       "  'Type of Quant. Measure': 0.19645390070921986,\n",
       "  'Units': 0.5216142467327302},\n",
       " 'detailed_results': {'Disease/Condition of Interest': {'precision': 0.29719101123595504,\n",
       "   'recall': 0.48554382744378155,\n",
       "   'f1': 0.3687053493640007,\n",
       "   'number': 2179},\n",
       "  'Dosage': {'precision': 0.5161550888529887,\n",
       "   'recall': 0.7375913813005002,\n",
       "   'f1': 0.6073182322192302,\n",
       "   'number': 2599},\n",
       "  'Drug Intervention': {'precision': 0.43245168759462105,\n",
       "   'recall': 0.6911471676629661,\n",
       "   'f1': 0.5320186250342371,\n",
       "   'number': 7026},\n",
       "  'Follow-up period': {'precision': 0.2511415525114155,\n",
       "   'recall': 0.35947712418300654,\n",
       "   'f1': 0.2956989247311828,\n",
       "   'number': 306},\n",
       "  'Group Characteristic': {'precision': 0.08151008151008152,\n",
       "   'recall': 0.05621301775147929,\n",
       "   'f1': 0.06653825949921205,\n",
       "   'number': 3380},\n",
       "  'Group Name': {'precision': 0.2523914643119941,\n",
       "   'recall': 0.3923362882470689,\n",
       "   'f1': 0.30717564088212246,\n",
       "   'number': 3497},\n",
       "  'Intervention Administration': {'precision': 0.47064989517819705,\n",
       "   'recall': 0.6479076479076479,\n",
       "   'f1': 0.5452337583485124,\n",
       "   'number': 693},\n",
       "  'Intervention Duration': {'precision': 0.4298688193743693,\n",
       "   'recall': 0.4570815450643777,\n",
       "   'f1': 0.44305772230889234,\n",
       "   'number': 932},\n",
       "  'Intervention Frequency': {'precision': 0.5920925747348119,\n",
       "   'recall': 0.4410919540229885,\n",
       "   'f1': 0.5055578427336351,\n",
       "   'number': 1392},\n",
       "  'Non-Pharmaceutical Intervention': {'precision': 0.2621359223300971,\n",
       "   'recall': 0.12980769230769232,\n",
       "   'f1': 0.17363344051446947,\n",
       "   'number': 208},\n",
       "  'Non-Study Drug': {'precision': 0.10704960835509138,\n",
       "   'recall': 0.30943396226415093,\n",
       "   'f1': 0.15906886517943744,\n",
       "   'number': 265},\n",
       "  'Outcome (Study Endpoint)': {'precision': 0.15534506089309877,\n",
       "   'recall': 0.105032021957914,\n",
       "   'f1': 0.12532751091703054,\n",
       "   'number': 5465},\n",
       "  'Qualitative Side Effects': {'precision': 0.0,\n",
       "   'recall': 0.0,\n",
       "   'f1': 0.0,\n",
       "   'number': 0},\n",
       "  'Quantitative Measurement': {'precision': 0.5858250276854928,\n",
       "   'recall': 0.45749938225846304,\n",
       "   'f1': 0.5137703780783905,\n",
       "   'number': 8094},\n",
       "  'Sample Size': {'precision': 0.7647907647907648,\n",
       "   'recall': 0.4793488091649081,\n",
       "   'f1': 0.5893254262416605,\n",
       "   'number': 3317},\n",
       "  'Side Effects': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 337},\n",
       "  'Statistical Significance': {'precision': 0.8912365777623831,\n",
       "   'recall': 0.6976681127982647,\n",
       "   'f1': 0.782661596958175,\n",
       "   'number': 3688},\n",
       "  'Study Duration': {'precision': 0.18429003021148035,\n",
       "   'recall': 0.5648148148148148,\n",
       "   'f1': 0.27790432801822323,\n",
       "   'number': 108},\n",
       "  'Study Years': {'precision': 0.5217391304347826,\n",
       "   'recall': 0.35714285714285715,\n",
       "   'f1': 0.42402826855123676,\n",
       "   'number': 168},\n",
       "  'Type of Quant. Measure': {'precision': 0.1943859649122807,\n",
       "   'recall': 0.1985663082437276,\n",
       "   'f1': 0.19645390070921986,\n",
       "   'number': 1395},\n",
       "  'Units': {'precision': 0.5794511805998723,\n",
       "   'recall': 0.47427526769391487,\n",
       "   'f1': 0.5216142467327302,\n",
       "   'number': 3829},\n",
       "  'overall_precision': 0.42624267716843983,\n",
       "  'overall_recall': 0.4450877695486722,\n",
       "  'overall_f1': 0.4354614329893812,\n",
       "  'overall_accuracy': 0.8101238359720483}}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pmid</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4080</td>\n",
       "      <td>0.859649</td>\n",
       "      <td>0.343750</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.423077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>388220</td>\n",
       "      <td>0.811881</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.347826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1642186</td>\n",
       "      <td>0.816199</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.423077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1336527</td>\n",
       "      <td>0.876364</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>694800</td>\n",
       "      <td>0.834286</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.421053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1474</th>\n",
       "      <td>35779610</td>\n",
       "      <td>0.778068</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.048780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1475</th>\n",
       "      <td>35801548</td>\n",
       "      <td>0.654321</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.478261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1476</th>\n",
       "      <td>36112808</td>\n",
       "      <td>0.869301</td>\n",
       "      <td>0.387097</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1477</th>\n",
       "      <td>36201632</td>\n",
       "      <td>0.781915</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.119048</td>\n",
       "      <td>0.178571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1478</th>\n",
       "      <td>36206137</td>\n",
       "      <td>0.880734</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.205128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1479 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          pmid  accuracy  precision    recall        f1\n",
       "0         4080  0.859649   0.343750  0.550000  0.423077\n",
       "1       388220  0.811881   0.400000  0.307692  0.347826\n",
       "2      1642186  0.816199   0.392857  0.458333  0.423077\n",
       "3      1336527  0.876364   0.461538  0.750000  0.571429\n",
       "4       694800  0.834286   0.333333  0.571429  0.421053\n",
       "...        ...       ...        ...       ...       ...\n",
       "1474  35779610  0.778068   0.066667  0.038462  0.048780\n",
       "1475  35801548  0.654321   0.500000  0.458333  0.478261\n",
       "1476  36112808  0.869301   0.387097  0.705882  0.500000\n",
       "1477  36201632  0.781915   0.357143  0.119048  0.178571\n",
       "1478  36206137  0.880734   0.181818  0.235294  0.205128\n",
       "\n",
       "[1479 rows x 5 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 2 : Few-shot-prompting : GPT retrieves an entity as many times as it appears in the abstract (no need for abbreviations either)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpt label --> trial_sieve label\n",
    "\n",
    "tag_to_label = {\n",
    "    \"Disease/Condition of Interest\" : 8, #\n",
    "    \"Dosage\" : 9, #\n",
    "    \"Drug Intervention\" : 1 , #\n",
    "    \"Follow-up period\" : 16, # \n",
    "    \"Group Characteristic\" : 6, # \n",
    "    \"Group Name\" : 3,#  \n",
    "    \"Sample Size\" : 7, # \n",
    "    \"Intervention Administration\" : 13, # \n",
    "    \"Intervention Duration\" : 12, # \n",
    "    \"Intervention Frequency\" : 11, #  \n",
    "    \"Non-Pharmaceutical Intervention\" : 17, # \n",
    "    \"Non-Study Drug\" : 14, # \n",
    "    \"Outcome (Study Endpoint)\" : 2, # \n",
    "    \"Side Effects\" : 15, # Side effects\n",
    "    \"Quantitative Measurement\" : 0, # \n",
    "    \"Statistical Significance\" : 5, #\n",
    "    \"Study Duration\" : 19, # \n",
    "    \"Study Years\" : 18, #\n",
    "    \"Type of Quant. Measure\" : 10, # \n",
    "    \"Units\" : 4, #\n",
    "}\n",
    "\n",
    "path_to_processed_for_modeling = \"/home2/cye73/gpt-meta-analysis/tests/processed_for_modeling.json\"\n",
    "with open(path_to_processed_for_modeling, \"r\") as file:\n",
    "    processed_for_modeling = ujson.load(file)\n",
    "documents = processed_for_modeling\n",
    "\n",
    "# path_to_gpt_output = '/home2/cye73/gpt-meta-analysis/tests/results/2024-06-28/16:48:07/extraction/output.jsonl'\n",
    "path_to_gpt_output = '/home2/cye73/gpt-meta-analysis/tests/results/2024-07-02/19:22:24/extraction/output.jsonl'\n",
    "\n",
    "gpt_output = []\n",
    "with open(path_to_gpt_output, 'r') as file:\n",
    "    for line in file:\n",
    "        gpt_output.append(json.loads(line))\n",
    "    \n",
    "gpt_pmids = [int(el['pmid']) for el in gpt_output]\n",
    "\n",
    "pmid_to_output = {entry['pmid']: entry for entry in gpt_output}\n",
    "\n",
    "# pmid_to_extracted_entities = {entry['pmid']: entry.get('entities', entry.get('labels')) for entry in gpt_output}\n",
    "pmid_to_extracted_entities = {entry['pmid']: entry['entities'] for entry in gpt_output}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tagged_text_v3(abstract, tagged_text):\n",
    "    '''\n",
    "    Function to extract the position of the tagged text from the abstract given its surrounding text\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    abstract : str\n",
    "        The abstract text\n",
    "    tagged_text : list of dict\n",
    "        The tagged text\n",
    "    tag_to_label : dict\n",
    "        Mapping of tags to labels\n",
    "    '''\n",
    "    output = []\n",
    "    missed = []\n",
    "    \n",
    "    for entity in tagged_text:\n",
    "        surrounding_text = entity[\"surrounding\"]\n",
    "        entity_text = entity[\"text\"]\n",
    "        \n",
    "        if entity[\"tag\"] not in tag_to_label:\n",
    "            continue\n",
    "        \n",
    "        # Handle special characters like non-breaking spaces\n",
    "        surrounding_text = surrounding_text.replace('\\xa0', ' ')\n",
    "        abstract = abstract.replace('\\xa0', ' ')\n",
    "        \n",
    "        # Find the start position of the surrounding text in the abstract\n",
    "        start_idx = abstract.lower().find(surrounding_text.lower())\n",
    "        \n",
    "        if start_idx != -1:\n",
    "            # Find the start position of the entity text within the surrounding text\n",
    "            surrounding_text_lower = surrounding_text.lower()\n",
    "            entity_text_lower = entity_text.lower()\n",
    "            \n",
    "            if entity_text.isdigit():\n",
    "                # Convert the number to words\n",
    "                entity_text_in_words = p.number_to_words(entity_text).lower()\n",
    "                # Check for both the number and its word representation\n",
    "                entity_start_in_surrounding = surrounding_text_lower.find(entity_text_lower)\n",
    "                found_form = \"numeric\"\n",
    "                if entity_start_in_surrounding == -1:\n",
    "                    entity_start_in_surrounding = surrounding_text_lower.find(entity_text_in_words)\n",
    "                    found_form = \"words\"\n",
    "            else:\n",
    "                entity_start_in_surrounding = surrounding_text_lower.find(entity_text_lower)\n",
    "                found_form = \"text\"\n",
    "            \n",
    "            if entity_start_in_surrounding != -1:\n",
    "                # Calculate the actual start and end positions in the abstract\n",
    "                actual_start_idx = start_idx + entity_start_in_surrounding\n",
    "                \n",
    "                if found_form == \"numeric\":\n",
    "                    actual_end_idx = actual_start_idx + len(entity_text)\n",
    "                elif found_form == \"words\":\n",
    "                    actual_end_idx = actual_start_idx + len(entity_text_in_words)\n",
    "                else:\n",
    "                    actual_end_idx = actual_start_idx + len(entity_text)\n",
    "                \n",
    "                output.append({\n",
    "                    \"start\": actual_start_idx,\n",
    "                    \"end\": actual_end_idx,\n",
    "                    \"label\": tag_to_label[entity[\"tag\"]],\n",
    "                    \"tag\": entity[\"tag\"],\n",
    "                    \"text\": entity[\"text\"]\n",
    "                })\n",
    "        else :\n",
    "            missed.append(entity)\n",
    "    \n",
    "    output.sort(key=lambda x: x[\"start\"])\n",
    "    return output, missed\n",
    "\n",
    "extraction_keys = [\n",
    "    \"disease\", \n",
    "    \"drug_intervention\", \n",
    "    \"drug_dosage\", \n",
    "    \"sample_size\", \n",
    "    \"follow_up_period\", \n",
    "    \"group_characteristic\", \n",
    "    \"group_name\", \n",
    "    \"intervention_administration\", \n",
    "    \"intervention_duration\", \n",
    "    \"intervention_frequency\", \n",
    "    \"non_pharmaceutical_intervention\", \n",
    "    \"non_study_drug\", \n",
    "    \"outcome\", \n",
    "    \"qualitative_side_effects\", \n",
    "    \"quantitative_measurement\", \n",
    "    \"statistical_significance\", \n",
    "    \"study_duration\", \n",
    "    \"study_years\", \n",
    "    \"type_of_quant_measure\", \n",
    "    \"units\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_seqeval_format(y_true, y_pred, abstract):\n",
    "    '''\n",
    "    This function converts the entity data to seqeval format\n",
    "    Parameters:\n",
    "    ----------\n",
    "    y_true : list\n",
    "        Human annotated data\n",
    "    y_pred : list\n",
    "        Model predictions\n",
    "    abstract : str\n",
    "        The abstract to convert to seqeval format\n",
    "    '''\n",
    "    def label_tokens(annotations, abstract):\n",
    "        tokens = abstract.split()\n",
    "        labels = [\"O\"] * len(tokens)\n",
    "        for ann in annotations:\n",
    "            start_idx = len(abstract[:ann['start']].split())\n",
    "            end_idx = start_idx + len(ann['text'].split())\n",
    "            labels[start_idx] = f\"B-{ann['tag']}\"\n",
    "            for i in range(start_idx + 1, end_idx):\n",
    "                labels[i] = f\"I-{ann['tag']}\"\n",
    "        return labels\n",
    "    \n",
    "    y_true_seqeval = label_tokens(y_true, abstract)\n",
    "    y_pred_seqeval = label_tokens(y_pred, abstract)\n",
    "    return y_true_seqeval, y_pred_seqeval\n",
    "\n",
    "def label_tokens_from_offsets(text, annotations):\n",
    "    doc = nlp(text)\n",
    "    tokens = [token.text for token in doc]\n",
    "    labels = [\"O\"] * len(tokens)\n",
    "\n",
    "    for ann in annotations:\n",
    "        start_char = ann['start']\n",
    "        end_char = ann['end']\n",
    "        start_token = next((i for i, token in enumerate(doc) if token.idx >= start_char), None)\n",
    "        end_token = next((i for i, token in enumerate(doc) if token.idx >= end_char), None)\n",
    "        \n",
    "        if start_token is not None and end_token is not None:\n",
    "            labels[start_token] = f\"B-{ann['tag']}\"\n",
    "            for i in range(start_token + 1, end_token):\n",
    "                labels[i] = f\"I-{ann['tag']}\"\n",
    "\n",
    "    return labels\n",
    "\n",
    "def compute_metrics_v2(pmids) :\n",
    "    all_y_true_seqeval = []\n",
    "    all_y_pred_seqeval = []\n",
    "    results_list = []\n",
    "    \n",
    "    for i in range(len(pmids)):\n",
    "        # if pmids[i] == 12608440 :\n",
    "        #     continue\n",
    "        abstract, true_spans = retrieve_abstract_and_spans(path_to_processed_for_modeling = path_to_processed_for_modeling, pmid = pmids[i])\n",
    "        pred_spans, missed = extract_tagged_text_v3(abstract=abstract, tagged_text=pmid_to_extracted_entities[f\"{pmids[i]}\"])\n",
    "    \n",
    "        y_true_seqeval = label_tokens_from_offsets(text = abstract, annotations = true_spans)\n",
    "        y_pred_seqeval = label_tokens_from_offsets(text = abstract, annotations = pred_spans)\n",
    "        all_y_true_seqeval.append(y_true_seqeval)\n",
    "        all_y_pred_seqeval.append(y_pred_seqeval)\n",
    "        results = seqeval.compute(predictions=[y_pred_seqeval], references=[y_true_seqeval])\n",
    "        results['pmid'] = pmids[i]\n",
    "        results_list.append(results)\n",
    "        \n",
    "        if i%100 == 0:\n",
    "            print(\"i :\", i)\n",
    "        \n",
    "\n",
    "    # Evaluate using seqeval\n",
    "    overall_results = seqeval.compute(predictions=all_y_pred_seqeval, references=all_y_true_seqeval)\n",
    "    overall_class_specific_f1 = {\n",
    "        k: v[\"f1\"] for k, v in overall_results.items() if not k.startswith(\"overall\")\n",
    "    }\n",
    "\n",
    "    \n",
    "    df_results = pd.DataFrame(results_list)\n",
    "    columns = ['pmid', 'overall_accuracy', 'overall_precision', 'overall_recall', 'overall_f1'] # + \\\n",
    "                    # [col for col in df_results.columns if col not in ['pmid', 'overall_accuracy', 'overall_precision', 'overall_recall', 'overall_f1']]\n",
    "    df_results = df_results[columns].rename(columns={\n",
    "        'overall_accuracy': 'accuracy',\n",
    "        'overall_precision': 'precision',\n",
    "        'overall_recall': 'recall',\n",
    "        'overall_f1': 'f1'\n",
    "    })\n",
    "    \n",
    "    return {\n",
    "        \"accuracy\": overall_results[\"overall_accuracy\"],\n",
    "        \"precision\": overall_results[\"overall_precision\"],\n",
    "        \"recall\": overall_results[\"overall_recall\"],\n",
    "        \"f1\": overall_results[\"overall_f1\"],\n",
    "        \"class_specific_f1\": overall_class_specific_f1,\n",
    "        \"detailed_results\": overall_results,\n",
    "    }, df_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i : 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cye73/.conda/envs/gpt-meta-analysis/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/cye73/.conda/envs/gpt-meta-analysis/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i : 100\n",
      "i : 200\n",
      "i : 300\n",
      "i : 400\n",
      "i : 500\n",
      "i : 600\n",
      "i : 700\n",
      "i : 800\n",
      "i : 900\n",
      "i : 1000\n",
      "i : 1100\n",
      "i : 1200\n",
      "i : 1300\n",
      "i : 1400\n"
     ]
    }
   ],
   "source": [
    "results2, df2 = compute_metrics_v2(pmids = gpt_pmids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8368118885756922,\n",
       " 'precision': 0.5470706529025339,\n",
       " 'recall': 0.46483493951199506,\n",
       " 'f1': 0.5026112233334975,\n",
       " 'class_specific_f1': {'Disease/Condition of Interest': 0.3642398760787785,\n",
       "  'Dosage': 0.74235807860262,\n",
       "  'Drug Intervention': 0.48937441324571135,\n",
       "  'Follow-up period': 0.3084886128364389,\n",
       "  'Group Characteristic': 0.16135414376786106,\n",
       "  'Group Name': 0.32184376912094637,\n",
       "  'Intervention Administration': 0.38641188959660294,\n",
       "  'Intervention Duration': 0.5233219567690557,\n",
       "  'Intervention Frequency': 0.5002742731760834,\n",
       "  'Non-Pharmaceutical Intervention': 0.21453287197231832,\n",
       "  'Non-Study Drug': 0.27426810477657937,\n",
       "  'Outcome (Study Endpoint)': 0.2227915556466489,\n",
       "  'Quantitative Measurement': 0.6225714285714286,\n",
       "  'Sample Size': 0.7972387221062771,\n",
       "  'Side Effects': 0.5577142857142857,\n",
       "  'Statistical Significance': 0.8854331958108537,\n",
       "  'Study Duration': 0.33142857142857146,\n",
       "  'Study Years': 0.5617977528089887,\n",
       "  'Type of Quant. Measure': 0.22426470588235295,\n",
       "  'Units': 0.4723120837297812},\n",
       " 'detailed_results': {'Disease/Condition of Interest': {'precision': 0.33757178014766204,\n",
       "   'recall': 0.39548294089380104,\n",
       "   'f1': 0.3642398760787785,\n",
       "   'number': 2081},\n",
       "  'Dosage': {'precision': 0.7169970476592156,\n",
       "   'recall': 0.7695789950203712,\n",
       "   'f1': 0.74235807860262,\n",
       "   'number': 2209},\n",
       "  'Drug Intervention': {'precision': 0.5424787133396405,\n",
       "   'recall': 0.44574004975124376,\n",
       "   'f1': 0.48937441324571135,\n",
       "   'number': 6432},\n",
       "  'Follow-up period': {'precision': 0.21285714285714286,\n",
       "   'recall': 0.5601503759398496,\n",
       "   'f1': 0.3084886128364389,\n",
       "   'number': 266},\n",
       "  'Group Characteristic': {'precision': 0.252233676975945,\n",
       "   'recall': 0.11861667744020685,\n",
       "   'f1': 0.16135414376786106,\n",
       "   'number': 3094},\n",
       "  'Group Name': {'precision': 0.44251261918115536,\n",
       "   'recall': 0.2528846153846154,\n",
       "   'f1': 0.32184376912094637,\n",
       "   'number': 3120},\n",
       "  'Intervention Administration': {'precision': 0.5967213114754099,\n",
       "   'recall': 0.2857142857142857,\n",
       "   'f1': 0.38641188959660294,\n",
       "   'number': 637},\n",
       "  'Intervention Duration': {'precision': 0.5038335158817087,\n",
       "   'recall': 0.5443786982248521,\n",
       "   'f1': 0.5233219567690557,\n",
       "   'number': 845},\n",
       "  'Intervention Frequency': {'precision': 0.7390599675850892,\n",
       "   'recall': 0.3781094527363184,\n",
       "   'f1': 0.5002742731760834,\n",
       "   'number': 1206},\n",
       "  'Non-Pharmaceutical Intervention': {'precision': 0.29523809523809524,\n",
       "   'recall': 0.16847826086956522,\n",
       "   'f1': 0.21453287197231832,\n",
       "   'number': 184},\n",
       "  'Non-Study Drug': {'precision': 0.20843091334894615,\n",
       "   'recall': 0.4009009009009009,\n",
       "   'f1': 0.27426810477657937,\n",
       "   'number': 222},\n",
       "  'Outcome (Study Endpoint)': {'precision': 0.22669447340980187,\n",
       "   'recall': 0.21902075357646586,\n",
       "   'f1': 0.2227915556466489,\n",
       "   'number': 4963},\n",
       "  'Quantitative Measurement': {'precision': 0.6382542472173404,\n",
       "   'recall': 0.6076408254322365,\n",
       "   'f1': 0.6225714285714286,\n",
       "   'number': 7172},\n",
       "  'Sample Size': {'precision': 0.7912683237731039,\n",
       "   'recall': 0.8032999029440311,\n",
       "   'f1': 0.7972387221062771,\n",
       "   'number': 3091},\n",
       "  'Side Effects': {'precision': 0.4295774647887324,\n",
       "   'recall': 0.7947882736156352,\n",
       "   'f1': 0.5577142857142857,\n",
       "   'number': 307},\n",
       "  'Statistical Significance': {'precision': 0.9250663129973474,\n",
       "   'recall': 0.8490566037735849,\n",
       "   'f1': 0.8854331958108537,\n",
       "   'number': 3286},\n",
       "  'Study Duration': {'precision': 0.37662337662337664,\n",
       "   'recall': 0.29591836734693877,\n",
       "   'f1': 0.33142857142857146,\n",
       "   'number': 98},\n",
       "  'Study Years': {'precision': 0.6,\n",
       "   'recall': 0.528169014084507,\n",
       "   'f1': 0.5617977528089887,\n",
       "   'number': 142},\n",
       "  'Type of Quant. Measure': {'precision': 0.40043763676148797,\n",
       "   'recall': 0.15574468085106383,\n",
       "   'f1': 0.22426470588235295,\n",
       "   'number': 1175},\n",
       "  'Units': {'precision': 0.6559196617336153,\n",
       "   'recall': 0.3690157597383289,\n",
       "   'f1': 0.4723120837297812,\n",
       "   'number': 3363},\n",
       "  'overall_precision': 0.5470706529025339,\n",
       "  'overall_recall': 0.46483493951199506,\n",
       "  'overall_f1': 0.5026112233334975,\n",
       "  'overall_accuracy': 0.8368118885756922}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pmid</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4080</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>361794</td>\n",
       "      <td>0.890547</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.424242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>388220</td>\n",
       "      <td>0.782178</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>476704</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.530612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>336116</td>\n",
       "      <td>0.823899</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.545455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1406</th>\n",
       "      <td>33456366</td>\n",
       "      <td>0.817391</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.595745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1407</th>\n",
       "      <td>33410912</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.482759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1408</th>\n",
       "      <td>33493729</td>\n",
       "      <td>0.827044</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.363636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1409</th>\n",
       "      <td>33502533</td>\n",
       "      <td>0.913889</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>0.721311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1410</th>\n",
       "      <td>33485594</td>\n",
       "      <td>0.863787</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.549020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1411 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          pmid  accuracy  precision    recall        f1\n",
       "0         4080  1.000000   1.000000  1.000000  1.000000\n",
       "1       361794  0.890547   0.368421  0.500000  0.424242\n",
       "2       388220  0.782178   0.473684  0.346154  0.400000\n",
       "3       476704  0.828571   0.541667  0.520000  0.530612\n",
       "4       336116  0.823899   0.600000  0.500000  0.545455\n",
       "...        ...       ...        ...       ...       ...\n",
       "1406  33456366  0.817391   0.583333  0.608696  0.595745\n",
       "1407  33410912  0.846154   0.875000  0.333333  0.482759\n",
       "1408  33493729  0.827044   0.400000  0.333333  0.363636\n",
       "1409  33502533  0.913889   0.687500  0.758621  0.721311\n",
       "1410  33485594  0.863787   0.823529  0.411765  0.549020\n",
       "\n",
       "[1411 rows x 5 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pmid</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>7484829</td>\n",
       "      <td>0.829971</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1073</th>\n",
       "      <td>22717420</td>\n",
       "      <td>0.819639</td>\n",
       "      <td>0.135135</td>\n",
       "      <td>0.138889</td>\n",
       "      <td>0.136986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1190</th>\n",
       "      <td>25448925</td>\n",
       "      <td>0.476071</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.098039</td>\n",
       "      <td>0.116279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1225</th>\n",
       "      <td>26510933</td>\n",
       "      <td>0.768293</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.085714</td>\n",
       "      <td>0.139535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1327</th>\n",
       "      <td>28729361</td>\n",
       "      <td>0.841146</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1331</th>\n",
       "      <td>28929323</td>\n",
       "      <td>0.876640</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.139535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>33849926</td>\n",
       "      <td>0.615764</td>\n",
       "      <td>0.121212</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.131148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1534</th>\n",
       "      <td>35483753</td>\n",
       "      <td>0.692494</td>\n",
       "      <td>0.108108</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.135593</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          pmid  accuracy  precision    recall        f1\n",
       "184    7484829  0.829971   0.125000  0.142857  0.133333\n",
       "1073  22717420  0.819639   0.135135  0.138889  0.136986\n",
       "1190  25448925  0.476071   0.142857  0.098039  0.116279\n",
       "1225  26510933  0.768293   0.375000  0.085714  0.139535\n",
       "1327  28729361  0.841146   0.125000  0.125000  0.125000\n",
       "1331  28929323  0.876640   0.136364  0.142857  0.139535\n",
       "1498  33849926  0.615764   0.121212  0.142857  0.131148\n",
       "1534  35483753  0.692494   0.108108  0.181818  0.135593"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df2 = df2[(df2[\"f1\"] < 0.15) & (df2[\"f1\"] > 0.10)]\n",
    "filtered_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cye73/.conda/envs/gpt-meta-analysis/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/cye73/.conda/envs/gpt-meta-analysis/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "pmid = 33583283\n",
    "abstract, true_spans = retrieve_abstract_and_spans(path_to_processed_for_modeling = path_to_processed_for_modeling, pmid = pmid)\n",
    "pred_spans, missed = extract_tagged_text_v3(abstract=abstract, tagged_text=pmid_to_extracted_entities[f\"{pmid}\"])\n",
    "\n",
    "y_true_seqeval = label_tokens_from_offsets(text = abstract, annotations = true_spans)\n",
    "y_pred_seqeval = label_tokens_from_offsets(text = abstract, annotations = pred_spans)\n",
    "results = seqeval.compute(predictions=[y_pred_seqeval], references=[y_true_seqeval])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"CT visual quantitative evaluation of hypertensive patients with coronavirus disease (COVID-19): Potential influence of angiotensin converting enzyme inhibitors / angiotensin receptor blockers on severity of lung involvement.\\nThere is not enough data on the effect of angiotensin-converting enzyme inhibitors (ACEIs)/angiotensin receptor blockers (ARBs) on lung involvement in patients with COVID-19 pneumonia and hypertension (HT). Our aim was to compare the lung involvement of the HT patients hospitalized for COVID-19 using ACEIs/ARBs with the patients taking other anti-HT medications. : Patients who have a diagnosis of HT among the patients treated for laboratory-confirmed COVID-19 between 31 March 2020 and 28 May 2020 were included in the study. One hundred and twenty-four patients were divided into two as ACEIs/ARBs group (n\\xa0=\\xa075) and non-ACEIs/ARBs group (n\\xa0=\\xa049) according to the anti-HT drug used. The chest CT involvement areas of these two groups were evaluated quantitatively by two observers including all lobes, and total severity score (TSS) was calculated. These TSS values were compared between drug groups and clinical groups. In clinical classification; there were 4 (%3.2) asymptomatic, 5 (4.0%) mild type, 92 (74.1%) common type, 14 (11.3%) severe type, 9 (7.3%) critical type patients. ACEI/ARB group's TSS (mean±SD, 7.74\\xa0±\\xa03.54) was statistically higher than other anti-HT medication group (mean±SD, 4.40\\xa0±\\xa01.89) (<i>p</i> <\\xa0.001). Likewise, severe-critical clinical type's TSS (mean±SD, 9.17\\xa0±\\xa03.44) was statistically higher than common type (mean±SD, 5.76\\xa0±\\xa03.07) (<i>p</i> <\\xa0.001). Excellent agreement was established between the two blinded observers in the TSS measurements. Quantitative evaluation of CT and TSS score can give an idea about the clinical classification of the patient. TSS is higher in ACEI/ARB group than non-ACEIs/ARBs group.\""
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'tag': 'Disease/Condition of Interest',\n",
       "  'text': 'hypertension',\n",
       "  'surrounding': 'patients with COVID-19 pneumonia and hypertension (HT)'},\n",
       " {'tag': 'Disease/Condition of Interest',\n",
       "  'text': 'COVID-19',\n",
       "  'surrounding': 'patients with COVID-19 pneumonia and hypertension (HT)'},\n",
       " {'tag': 'Drug Intervention',\n",
       "  'text': 'angiotensin-converting enzyme inhibitors',\n",
       "  'surrounding': 'effect of angiotensin-converting enzyme inhibitors (ACEIs)'},\n",
       " {'tag': 'Drug Intervention',\n",
       "  'text': 'angiotensin receptor blockers',\n",
       "  'surrounding': 'angiotensin receptor blockers (ARBs)'},\n",
       " {'tag': 'Sample Size',\n",
       "  'text': 'One hundred and twenty-four',\n",
       "  'surrounding': 'One hundred and twenty-four patients were divided'},\n",
       " {'tag': 'Group Name',\n",
       "  'text': 'ACEIs/ARBs group',\n",
       "  'surrounding': 'as ACEIs/ARBs group (n = 75)'},\n",
       " {'tag': 'Group Name',\n",
       "  'text': 'non-ACEIs/ARBs group',\n",
       "  'surrounding': 'non-ACEIs/ARBs group (n = 49)'},\n",
       " {'tag': 'Quantitative Measurement',\n",
       "  'text': '75',\n",
       "  'surrounding': 'ACEIs/ARBs group (n = 75)'},\n",
       " {'tag': 'Quantitative Measurement',\n",
       "  'text': '49',\n",
       "  'surrounding': 'non-ACEIs/ARBs group (n = 49)'},\n",
       " {'tag': 'Quantitative Measurement',\n",
       "  'text': '4',\n",
       "  'surrounding': 'there were 4 (%3.2) asymptomatic'},\n",
       " {'tag': 'Quantitative Measurement',\n",
       "  'text': '5',\n",
       "  'surrounding': '5 (4.0%) mild type'},\n",
       " {'tag': 'Quantitative Measurement',\n",
       "  'text': '92',\n",
       "  'surrounding': '92 (74.1%) common type'},\n",
       " {'tag': 'Quantitative Measurement',\n",
       "  'text': '14',\n",
       "  'surrounding': '14 (11.3%) severe type'},\n",
       " {'tag': 'Quantitative Measurement',\n",
       "  'text': '9',\n",
       "  'surrounding': '9 (7.3%) critical type'},\n",
       " {'tag': 'Quantitative Measurement',\n",
       "  'text': '3.2%',\n",
       "  'surrounding': '4 (%3.2) asymptomatic'},\n",
       " {'tag': 'Quantitative Measurement',\n",
       "  'text': '4.0%',\n",
       "  'surrounding': '5 (4.0%) mild type'},\n",
       " {'tag': 'Quantitative Measurement',\n",
       "  'text': '74.1%',\n",
       "  'surrounding': '92 (74.1%) common type'},\n",
       " {'tag': 'Quantitative Measurement',\n",
       "  'text': '11.3%',\n",
       "  'surrounding': '14 (11.3%) severe type'},\n",
       " {'tag': 'Quantitative Measurement',\n",
       "  'text': '7.3%',\n",
       "  'surrounding': '9 (7.3%) critical type'},\n",
       " {'tag': 'Quantitative Measurement',\n",
       "  'text': '7.74',\n",
       "  'surrounding': \"ACEI/ARB group's TSS (mean±SD, 7.74 ± 3.54)\"},\n",
       " {'tag': 'Quantitative Measurement',\n",
       "  'text': '3.54',\n",
       "  'surrounding': \"ACEI/ARB group's TSS (mean±SD, 7.74 ± 3.54)\"},\n",
       " {'tag': 'Quantitative Measurement',\n",
       "  'text': '4.40',\n",
       "  'surrounding': 'other anti-HT medication group (mean±SD, 4.40 ± 1.89)'},\n",
       " {'tag': 'Quantitative Measurement',\n",
       "  'text': '1.89',\n",
       "  'surrounding': 'other anti-HT medication group (mean±SD, 4.40 ± 1.89)'},\n",
       " {'tag': 'Statistical Significance',\n",
       "  'text': 'p < .001',\n",
       "  'surrounding': 'other anti-HT medication group (mean±SD, 4.40 ± 1.89) (p < .001)'},\n",
       " {'tag': 'Quantitative Measurement',\n",
       "  'text': '9.17',\n",
       "  'surrounding': \"severe-critical clinical type's TSS (mean±SD, 9.17 ± 3.44)\"},\n",
       " {'tag': 'Quantitative Measurement',\n",
       "  'text': '3.44',\n",
       "  'surrounding': \"severe-critical clinical type's TSS (mean±SD, 9.17 ± 3.44)\"},\n",
       " {'tag': 'Quantitative Measurement',\n",
       "  'text': '5.76',\n",
       "  'surrounding': 'common type (mean±SD, 5.76 ± 3.07)'},\n",
       " {'tag': 'Quantitative Measurement',\n",
       "  'text': '3.07',\n",
       "  'surrounding': 'common type (mean±SD, 5.76 ± 3.07)'},\n",
       " {'tag': 'Statistical Significance',\n",
       "  'text': 'p < .001',\n",
       "  'surrounding': 'common type (mean±SD, 5.76 ± 3.07) (p < .001)'},\n",
       " {'tag': 'Study Years',\n",
       "  'text': '31 March 2020 and 28 May 2020',\n",
       "  'surrounding': 'between 31 March 2020 and 28 May 2020'},\n",
       " {'tag': 'Outcome (Study Endpoint)',\n",
       "  'text': 'TSS',\n",
       "  'surrounding': 'TSS values were compared between drug groups'},\n",
       " {'tag': 'Outcome (Study Endpoint)',\n",
       "  'text': 'clinical classification',\n",
       "  'surrounding': 'clinical classification of the patient'}]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pmid_to_extracted_entities[f\"{pmid}\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'start': 267,\n",
       "  'end': 307,\n",
       "  'label': 1,\n",
       "  'tag': 'Drug Intervention',\n",
       "  'text': 'angiotensin-converting enzyme inhibitors'},\n",
       " {'start': 316,\n",
       "  'end': 345,\n",
       "  'label': 1,\n",
       "  'tag': 'Drug Intervention',\n",
       "  'text': 'angiotensin receptor blockers'},\n",
       " {'start': 390,\n",
       "  'end': 398,\n",
       "  'label': 8,\n",
       "  'tag': 'Disease/Condition of Interest',\n",
       "  'text': 'COVID-19'},\n",
       " {'start': 413,\n",
       "  'end': 425,\n",
       "  'label': 8,\n",
       "  'tag': 'Disease/Condition of Interest',\n",
       "  'text': 'hypertension'},\n",
       " {'start': 697,\n",
       "  'end': 726,\n",
       "  'label': 18,\n",
       "  'tag': 'Study Years',\n",
       "  'text': '31 March 2020 and 28 May 2020'},\n",
       " {'start': 755,\n",
       "  'end': 782,\n",
       "  'label': 7,\n",
       "  'tag': 'Sample Size',\n",
       "  'text': 'One hundred and twenty-four'},\n",
       " {'start': 817,\n",
       "  'end': 833,\n",
       "  'label': 3,\n",
       "  'tag': 'Group Name',\n",
       "  'text': 'ACEIs/ARBs group'},\n",
       " {'start': 839,\n",
       "  'end': 841,\n",
       "  'label': 0,\n",
       "  'tag': 'Quantitative Measurement',\n",
       "  'text': '75'},\n",
       " {'start': 847,\n",
       "  'end': 867,\n",
       "  'label': 3,\n",
       "  'tag': 'Group Name',\n",
       "  'text': 'non-ACEIs/ARBs group'},\n",
       " {'start': 873,\n",
       "  'end': 875,\n",
       "  'label': 0,\n",
       "  'tag': 'Quantitative Measurement',\n",
       "  'text': '49'},\n",
       " {'start': 1085,\n",
       "  'end': 1088,\n",
       "  'label': 2,\n",
       "  'tag': 'Outcome (Study Endpoint)',\n",
       "  'text': 'TSS'},\n",
       " {'start': 1190,\n",
       "  'end': 1191,\n",
       "  'label': 0,\n",
       "  'tag': 'Quantitative Measurement',\n",
       "  'text': '4'},\n",
       " {'start': 1213,\n",
       "  'end': 1214,\n",
       "  'label': 0,\n",
       "  'tag': 'Quantitative Measurement',\n",
       "  'text': '5'},\n",
       " {'start': 1216,\n",
       "  'end': 1220,\n",
       "  'label': 0,\n",
       "  'tag': 'Quantitative Measurement',\n",
       "  'text': '4.0%'},\n",
       " {'start': 1233,\n",
       "  'end': 1235,\n",
       "  'label': 0,\n",
       "  'tag': 'Quantitative Measurement',\n",
       "  'text': '92'},\n",
       " {'start': 1237,\n",
       "  'end': 1242,\n",
       "  'label': 0,\n",
       "  'tag': 'Quantitative Measurement',\n",
       "  'text': '74.1%'},\n",
       " {'start': 1257,\n",
       "  'end': 1259,\n",
       "  'label': 0,\n",
       "  'tag': 'Quantitative Measurement',\n",
       "  'text': '14'},\n",
       " {'start': 1261,\n",
       "  'end': 1266,\n",
       "  'label': 0,\n",
       "  'tag': 'Quantitative Measurement',\n",
       "  'text': '11.3%'},\n",
       " {'start': 1281,\n",
       "  'end': 1282,\n",
       "  'label': 0,\n",
       "  'tag': 'Quantitative Measurement',\n",
       "  'text': '9'},\n",
       " {'start': 1284,\n",
       "  'end': 1288,\n",
       "  'label': 0,\n",
       "  'tag': 'Quantitative Measurement',\n",
       "  'text': '7.3%'},\n",
       " {'start': 1346,\n",
       "  'end': 1350,\n",
       "  'label': 0,\n",
       "  'tag': 'Quantitative Measurement',\n",
       "  'text': '7.74'},\n",
       " {'start': 1354,\n",
       "  'end': 1358,\n",
       "  'label': 0,\n",
       "  'tag': 'Quantitative Measurement',\n",
       "  'text': '3.54'},\n",
       " {'start': 1432,\n",
       "  'end': 1436,\n",
       "  'label': 0,\n",
       "  'tag': 'Quantitative Measurement',\n",
       "  'text': '4.40'},\n",
       " {'start': 1440,\n",
       "  'end': 1444,\n",
       "  'label': 0,\n",
       "  'tag': 'Quantitative Measurement',\n",
       "  'text': '1.89'},\n",
       " {'start': 1522,\n",
       "  'end': 1526,\n",
       "  'label': 0,\n",
       "  'tag': 'Quantitative Measurement',\n",
       "  'text': '9.17'},\n",
       " {'start': 1530,\n",
       "  'end': 1534,\n",
       "  'label': 0,\n",
       "  'tag': 'Quantitative Measurement',\n",
       "  'text': '3.44'},\n",
       " {'start': 1589,\n",
       "  'end': 1593,\n",
       "  'label': 0,\n",
       "  'tag': 'Quantitative Measurement',\n",
       "  'text': '5.76'},\n",
       " {'start': 1597,\n",
       "  'end': 1601,\n",
       "  'label': 0,\n",
       "  'tag': 'Quantitative Measurement',\n",
       "  'text': '3.07'},\n",
       " {'start': 1788,\n",
       "  'end': 1811,\n",
       "  'label': 2,\n",
       "  'tag': 'Outcome (Study Endpoint)',\n",
       "  'text': 'clinical classification'}]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'tag': 'Quantitative Measurement',\n",
       "  'text': '3.2%',\n",
       "  'surrounding': '4 (%3.2) asymptomatic'},\n",
       " {'tag': 'Statistical Significance',\n",
       "  'text': 'p < .001',\n",
       "  'surrounding': 'other anti-HT medication group (mean±SD, 4.40 ± 1.89) (p < .001)'},\n",
       " {'tag': 'Statistical Significance',\n",
       "  'text': 'p < .001',\n",
       "  'surrounding': 'common type (mean±SD, 5.76 ± 3.07) (p < .001)'}]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Disease/Condition of Interest': {'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1': 0.0,\n",
       "  'number': 1},\n",
       " 'Drug Intervention': {'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1': 0.0,\n",
       "  'number': 4},\n",
       " 'Group Characteristic': {'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1': 0.0,\n",
       "  'number': 5},\n",
       " 'Group Name': {'precision': 1.0,\n",
       "  'recall': 0.3333333333333333,\n",
       "  'f1': 0.5,\n",
       "  'number': 6},\n",
       " 'Intervention Duration': {'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1': 0.0,\n",
       "  'number': 1},\n",
       " 'Outcome (Study Endpoint)': {'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1': 0.0,\n",
       "  'number': 4},\n",
       " 'Quantitative Measurement': {'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1': 0.0,\n",
       "  'number': 5},\n",
       " 'Sample Size': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 4},\n",
       " 'Statistical Significance': {'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1': 0.0,\n",
       "  'number': 2},\n",
       " 'Study Years': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 0},\n",
       " 'Type of Quant. Measure': {'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1': 0.0,\n",
       "  'number': 4},\n",
       " 'overall_precision': 0.06896551724137931,\n",
       " 'overall_recall': 0.05555555555555555,\n",
       " 'overall_f1': 0.061538461538461535,\n",
       " 'overall_accuracy': 0.6675062972292192}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt-meta-analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
